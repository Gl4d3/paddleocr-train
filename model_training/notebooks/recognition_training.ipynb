{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a87938",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Meter Reading Recognition Model Training\n",
    "# \n",
    "# This notebook provides an interactive way to train recognition models for meter reading using PaddleOCR.\n",
    "\n",
    "# ## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image, clear_output\n",
    "import numpy as np\n",
    "\n",
    "# Ensure we're in the PaddleOCR root directory\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../..\"))\n",
    "os.chdir(ROOT_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if key directories exist\n",
    "assert os.path.exists('ppocr'), \"Not in PaddleOCR root directory!\"\n",
    "assert os.path.exists('tools'), \"PaddleOCR tools directory not found!\"\n",
    "\n",
    "# ## 2. Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7723b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Default dataset paths (can be changed)\n",
    "REC_DATASET_DIR = \"dataset/rec_dataset_1\"\n",
    "DET_DATASET_DIR = \"dataset/det_dataset_1\"\n",
    "TRAIN_DATA_DIR = \"train_data/meter_detection\"\n",
    "\n",
    "# Cell for selecting dataset (edit these variables)\n",
    "rec_dataset_dir = REC_DATASET_DIR  # Change this to your recognition dataset directory\n",
    "det_dataset_dir = DET_DATASET_DIR  # Change this to your detection dataset directory \n",
    "train_data_dir = TRAIN_DATA_DIR    # Change this to your train data directory\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(rec_dataset_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(rec_dataset_dir, \"images\"), exist_ok=True)\n",
    "\n",
    "# Check if recognition dataset exists\n",
    "if not os.path.exists(os.path.join(rec_dataset_dir, \"train_list.txt\")) or not os.path.exists(os.path.join(rec_dataset_dir, \"test_list.txt\")):\n",
    "    print(f\"Recognition dataset not found in {rec_dataset_dir}.\")\n",
    "    print(\"You'll need to create it by extracting text regions from detection results.\")\n",
    "else:\n",
    "    # Count image files and labels\n",
    "    train_labels = os.path.join(rec_dataset_dir, \"train_list.txt\")\n",
    "    test_labels = os.path.join(rec_dataset_dir, \"test_list.txt\")\n",
    "    \n",
    "    train_count = 0\n",
    "    test_count = 0\n",
    "    \n",
    "    if os.path.exists(train_labels):\n",
    "        with open(train_labels, 'r') as f:\n",
    "            train_count = len(f.readlines())\n",
    "    \n",
    "    if os.path.exists(test_labels):\n",
    "        with open(test_labels, 'r') as f:\n",
    "            test_count = len(f.readlines())\n",
    "    \n",
    "    images_count = len(glob.glob(os.path.join(rec_dataset_dir, \"images/*.jpg\")))\n",
    "    \n",
    "    print(f\"Recognition dataset statistics:\")\n",
    "    print(f\"  - Training samples: {train_count}\")\n",
    "    print(f\"  - Test samples: {test_count}\")\n",
    "    print(f\"  - Image files: {images_count}\")\n",
    "    \n",
    "    # Check if placeholder labels are present\n",
    "    if train_count > 0:\n",
    "        with open(train_labels, 'r') as f:\n",
    "            first_line = f.readline().strip()\n",
    "            if \"###\" in first_line:\n",
    "                print(\"\\nWARNING: Dataset contains placeholder labels ('###').\")\n",
    "                print(\"You need to replace them with actual text labels before training.\")\n",
    "\n",
    "# ## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract recognition dataset from detection results if needed\n",
    "def extract_recognition_dataset():\n",
    "    \"\"\"Extract recognition dataset from detection results\"\"\"\n",
    "    if not os.path.exists(det_dataset_dir):\n",
    "        print(f\"Error: Detection dataset not found at {det_dataset_dir}\")\n",
    "        return False\n",
    "    \n",
    "    if not os.path.exists(os.path.join(train_data_dir, \"train_label.txt\")) or not os.path.exists(os.path.join(train_data_dir, \"test_label.txt\")):\n",
    "        print(f\"Error: Detection labels not found in {train_data_dir}\")\n",
    "        return False\n",
    "    \n",
    "    extract_cmd = f\"\"\"python model_training/rec_train/scripts/extract_meter_readings.py \\\n",
    "        --det_data_dir={det_dataset_dir} \\\n",
    "        --rec_output_dir={rec_dataset_dir} \\\n",
    "        --train_data={os.path.join(train_data_dir, \"train_label.txt\")} \\\n",
    "        --test_data={os.path.join(train_data_dir, \"test_label.txt\")} \\\n",
    "        --margin=5\"\"\"\n",
    "    \n",
    "    print(f\"Extraction command: {extract_cmd}\")\n",
    "    \n",
    "    # Uncomment to actually run the extraction\n",
    "    # result = subprocess.run(extract_cmd, shell=True)\n",
    "    # return result.returncode == 0\n",
    "    \n",
    "    print(\"Extraction command is ready. Uncomment to execute.\")\n",
    "    return False\n",
    "\n",
    "# Check if dataset needs to be extracted\n",
    "if not os.path.exists(os.path.join(rec_dataset_dir, \"train_list.txt\")) or not os.path.exists(os.path.join(rec_dataset_dir, \"test_list.txt\")):\n",
    "    print(\"Recognition dataset not found. Preparing extraction command.\")\n",
    "    extracted = extract_recognition_dataset()\n",
    "    if extracted:\n",
    "        print(\"Recognition dataset extraction completed successfully.\")\n",
    "    else:\n",
    "        print(\"Dataset extraction prepared but not executed. Uncomment to run.\")\n",
    "else:\n",
    "    print(\"Recognition dataset already exists. Skipping extraction.\")\n",
    "\n",
    "# ## 4. Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ca8fe",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualize recognition dataset\n",
    "def visualize_recognition_dataset(dataset_dir, max_samples=5):\n",
    "    \"\"\"Visualize samples from the recognition dataset\"\"\"\n",
    "    train_list = os.path.join(dataset_dir, \"train_list.txt\")\n",
    "    \n",
    "    if not os.path.exists(train_list):\n",
    "        print(f\"Training list not found: {train_list}\")\n",
    "        return\n",
    "    \n",
    "    with open(train_list, 'r') as f:\n",
    "        samples = f.readlines()\n",
    "    \n",
    "    # Randomly select samples to visualize\n",
    "    if len(samples) > max_samples:\n",
    "        samples = random.sample(samples, max_samples)\n",
    "    \n",
    "    print(f\"Visualizing {len(samples)} samples from recognition dataset:\")\n",
    "    \n",
    "    for i, sample in enumerate(samples):\n",
    "        parts = sample.strip().split('\\t')\n",
    "        if len(parts) >= 2:\n",
    "            img_path = parts[0]\n",
    "            label = parts[1]\n",
    "            \n",
    "            full_img_path = os.path.join(dataset_dir, \"images\", img_path)\n",
    "            if os.path.exists(full_img_path):\n",
    "                print(f\"Sample {i+1}: {img_path}, Label: {label}\")\n",
    "                display(Image(filename=full_img_path))\n",
    "            else:\n",
    "                print(f\"Image not found: {full_img_path}\")\n",
    "\n",
    "# Uncomment to visualize dataset\n",
    "# visualize_recognition_dataset(rec_dataset_dir)\n",
    "\n",
    "# ## 5. Character Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check character dictionary\n",
    "dict_path = \"model_training/rec_train/meter_dict.txt\"\n",
    "\n",
    "if not os.path.exists(dict_path):\n",
    "    print(f\"Character dictionary not found: {dict_path}\")\n",
    "    print(\"Creating a default dictionary with digits and common symbols...\")\n",
    "    \n",
    "    # Create default dictionary\n",
    "    default_chars = \"0123456789.,-/:\"\n",
    "    os.makedirs(os.path.dirname(dict_path), exist_ok=True)\n",
    "    \n",
    "    with open(dict_path, 'w') as f:\n",
    "        for char in default_chars:\n",
    "            f.write(f\"{char}\\n\")\n",
    "    \n",
    "    print(f\"Created default dictionary with {len(default_chars)} characters: {default_chars}\")\n",
    "else:\n",
    "    # Read existing dictionary\n",
    "    with open(dict_path, 'r') as f:\n",
    "        chars = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"Character dictionary found with {len(chars)} characters:\")\n",
    "    print(''.join(chars))\n",
    "\n",
    "# ## 6. Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be8d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training configuration\n",
    "# You can modify these parameters\n",
    "config = {\n",
    "    # Basic parameters\n",
    "    \"mode\": \"standard\",  # \"standard\" or \"distillation\"\n",
    "    \"gpu_ids\": \"0\",      # Comma-separated GPU IDs\n",
    "    \"max_epochs\": 500,   # Maximum epochs\n",
    "    \n",
    "    # Dataset parameters\n",
    "    \"rec_dataset_dir\": rec_dataset_dir,\n",
    "    \n",
    "    # Learning parameters\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"save_epoch_step\": 5,\n",
    "    \"eval_batch_step\": 500,\n",
    "    \n",
    "    # Model parameters\n",
    "    \"pretrained_model\": \"pretrain_models/en_PP-OCRv3_rec_train/best_accuracy\",\n",
    "    \"dict_path\": dict_path,\n",
    "    \"model_save_dir\": \"./model_training/rec_train/output/meter_rec\",  # For standard mode\n",
    "}\n",
    "\n",
    "# Update parameters based on mode\n",
    "if config[\"mode\"] == \"distillation\":\n",
    "    config[\"model_save_dir\"] = \"./model_training/rec_train/output/meter_rec_distillation\"\n",
    "\n",
    "# Print configuration\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# ## 7. Download Pretrained Model (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check and download pretrained model if needed\n",
    "def check_download_pretrained(pretrained_path):\n",
    "    \"\"\"Check if pretrained model exists, download if needed\"\"\"\n",
    "    if os.path.exists(pretrained_path) or os.path.exists(f\"{pretrained_path}.pdparams\"):\n",
    "        print(f\"Pretrained model found at {pretrained_path}\")\n",
    "        return True\n",
    "    \n",
    "    # For built-in pretrained models, download them\n",
    "    if pretrained_path.startswith(\"pretrain_models/\"):\n",
    "        model_name = pretrained_path.split(\"/\")[1]\n",
    "        print(f\"Downloading pretrained model: {model_name}\")\n",
    "        \n",
    "        # Different download URLs based on model type\n",
    "        if \"en_PP-OCRv3_rec_train\" in model_name:\n",
    "            url = \"https://paddleocr.bj.bcebos.com/PP-OCRv3/english/en_PP-OCRv3_rec_train.tar\"\n",
    "        else:\n",
    "            print(f\"Unknown pretrained model: {model_name}\")\n",
    "            return False\n",
    "        \n",
    "        # Create directory and download\n",
    "        os.makedirs(\"pretrain_models\", exist_ok=True)\n",
    "        download_cmd = f\"wget {url} -P pretrain_models/\"\n",
    "        extract_cmd = f\"tar -xf pretrain_models/{os.path.basename(url)} -C pretrain_models/\"\n",
    "        \n",
    "        print(f\"Running: {download_cmd}\")\n",
    "        subprocess.run(download_cmd, shell=True)\n",
    "        \n",
    "        print(f\"Running: {extract_cmd}\")\n",
    "        subprocess.run(extract_cmd, shell=True)\n",
    "        \n",
    "        return os.path.exists(pretrained_path) or os.path.exists(f\"{pretrained_path}.pdparams\")\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Check pretrained model\n",
    "if not check_download_pretrained(config[\"pretrained_model\"]):\n",
    "    print(f\"Warning: Pretrained model {config['pretrained_model']} not found and couldn't be downloaded.\")\n",
    "    print(\"You may need to download it manually or specify a different pretrained model.\")\n",
    "\n",
    "# ## 8. Prepare Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare config files for training\n",
    "def prepare_config_files():\n",
    "    \"\"\"Copy and prepare configuration files\"\"\"\n",
    "    # Create config directory\n",
    "    config_dir = \"configs/rec/meter\"\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    \n",
    "    # Copy standard and distillation config files\n",
    "    config_files = {\n",
    "        \"standard\": \"model_training/rec_train/configs/meter_PP-OCRv3_rec.yml\",\n",
    "        \"distillation\": \"model_training/rec_train/configs/meter_PP-OCRv3_rec_distillation.yml\"\n",
    "    }\n",
    "    \n",
    "    for mode, source in config_files.items():\n",
    "        if os.path.exists(source):\n",
    "            target = os.path.join(config_dir, os.path.basename(source))\n",
    "            copy_cmd = f\"cp {source} {target}\"\n",
    "            print(f\"Copying config {source} to {target}\")\n",
    "            subprocess.run(copy_cmd, shell=True)\n",
    "        else:\n",
    "            print(f\"Config file not found: {source}\")\n",
    "    \n",
    "    # Copy character dictionary to utils directory\n",
    "    dict_target = \"ppocr/utils/meter_dict.txt\"\n",
    "    os.makedirs(os.path.dirname(dict_target), exist_ok=True)\n",
    "    if os.path.exists(config[\"dict_path\"]):\n",
    "        copy_cmd = f\"cp {config['dict_path']} {dict_target}\"\n",
    "        print(f\"Copying dictionary to {dict_target}\")\n",
    "        subprocess.run(copy_cmd, shell=True)\n",
    "\n",
    "# Prepare config files\n",
    "prepare_config_files()\n",
    "\n",
    "# ## 9. Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate training command\n",
    "def generate_training_cmd(config):\n",
    "    \"\"\"Generate the training command based on configuration\"\"\"\n",
    "    if config[\"mode\"] == \"standard\":\n",
    "        cmd = f\"\"\"python -m paddle.distributed.launch --gpus='{config[\"gpu_ids\"]}' tools/train.py \\\n",
    "            -c configs/rec/meter/meter_PP-OCRv3_rec.yml \\\n",
    "            -o Global.pretrained_model={config[\"pretrained_model\"]} \\\n",
    "            Global.character_dict_path={config[\"dict_path\"]} \\\n",
    "            Global.save_model_dir={config[\"model_save_dir\"]} \\\n",
    "            Train.dataset.data_dir={config[\"rec_dataset_dir\"]} \\\n",
    "            Train.dataset.label_file_list=['{os.path.join(config[\"rec_dataset_dir\"], \"train_list.txt\")}'] \\\n",
    "            Eval.dataset.data_dir={config[\"rec_dataset_dir\"]} \\\n",
    "            Eval.dataset.label_file_list=['{os.path.join(config[\"rec_dataset_dir\"], \"test_list.txt\")}'] \\\n",
    "            Train.loader.batch_size_per_card={config[\"batch_size\"]} \\\n",
    "            Optimizer.lr.values=[{config[\"learning_rate\"]},{config[\"learning_rate\"]/10}] \\\n",
    "            Global.epoch_num={config[\"max_epochs\"]} \\\n",
    "            Global.save_epoch_step={config[\"save_epoch_step\"]} \\\n",
    "            Global.eval_batch_step=[0, {config[\"eval_batch_step\"]}]\"\"\"\n",
    "    else:  # distillation mode\n",
    "        cmd = f\"\"\"python -m paddle.distributed.launch --gpus='{config[\"gpu_ids\"]}' tools/train.py \\\n",
    "            -c configs/rec/meter/meter_PP-OCRv3_rec_distillation.yml \\\n",
    "            -o Architecture.Models.Teacher.pretrained={config[\"pretrained_model\"]} \\\n",
    "            Architecture.Models.Student.pretrained={config[\"pretrained_model\"]} \\\n",
    "            Global.character_dict_path={config[\"dict_path\"]} \\\n",
    "            Global.save_model_dir={config[\"model_save_dir\"]} \\\n",
    "            Train.dataset.data_dir={config[\"rec_dataset_dir\"]} \\\n",
    "            Train.dataset.label_file_list=['{os.path.join(config[\"rec_dataset_dir\"], \"train_list.txt\")}'] \\\n",
    "            Eval.dataset.data_dir={config[\"rec_dataset_dir\"]} \\\n",
    "            Eval.dataset.label_file_list=['{os.path.join(config[\"rec_dataset_dir\"], \"test_list.txt\")}'] \\\n",
    "            Train.loader.batch_size_per_card={config[\"batch_size\"]} \\\n",
    "            Optimizer.lr.values=[{config[\"learning_rate\"]},{config[\"learning_rate\"]/10}] \\\n",
    "            Global.epoch_num={config[\"max_epochs\"]} \\\n",
    "            Global.save_epoch_step={config[\"save_epoch_step\"]} \\\n",
    "            Global.eval_batch_step=[0, {config[\"eval_batch_step\"]}]\"\"\"\n",
    "    return cmd\n",
    "\n",
    "training_cmd = generate_training_cmd(config)\n",
    "print(\"Generated training command:\")\n",
    "print(training_cmd)\n",
    "\n",
    "# Uncomment the following to execute training\n",
    "# def run_with_output(cmd):\n",
    "#     \"\"\"Run a command and display output in real-time\"\"\"\n",
    "#     process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "#     for line in iter(process.stdout.readline, ''):\n",
    "#         print(line, end='')\n",
    "#     return process.wait()\n",
    "# \n",
    "# print(\"Starting training...\")\n",
    "# run_with_output(training_cmd)\n",
    "\n",
    "# ## 10. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9ae598",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation after training\n",
    "def generate_eval_cmd(config):\n",
    "    \"\"\"Generate evaluation command\"\"\"\n",
    "    model_dir = config[\"model_save_dir\"]\n",
    "    eval_cmd = f\"\"\"python tools/eval.py \\\n",
    "        -c configs/rec/meter/meter_PP-OCRv3_rec.yml \\\n",
    "        -o Global.checkpoints={model_dir}/best_accuracy \\\n",
    "        Global.character_dict_path={config[\"dict_path\"]} \\\n",
    "        Eval.dataset.data_dir={config[\"rec_dataset_dir\"]} \\\n",
    "        Eval.dataset.label_file_list=['{os.path.join(config[\"rec_dataset_dir\"], \"test_list.txt\")}']\"\"\"\n",
    "    return eval_cmd\n",
    "\n",
    "eval_cmd = generate_eval_cmd(config)\n",
    "print(\"Evaluation command:\")\n",
    "print(eval_cmd)\n",
    "\n",
    "# Uncomment to run evaluation\n",
    "# print(\"Running evaluation...\")\n",
    "# run_with_output(eval_cmd)\n",
    "\n",
    "# ## 11. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1dad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run inference on a sample image\n",
    "def generate_infer_cmd(config, sample_image):\n",
    "    \"\"\"Generate inference command for a sample image\"\"\"\n",
    "    model_dir = config[\"model_save_dir\"]\n",
    "    infer_cmd = f\"\"\"python tools/infer_rec.py \\\n",
    "        -c configs/rec/meter/meter_PP-OCRv3_rec.yml \\\n",
    "        -o Global.infer_img={sample_image} \\\n",
    "        Global.checkpoints={model_dir}/best_accuracy \\\n",
    "        Global.character_dict_path={config[\"dict_path\"]}\"\"\"\n",
    "    return infer_cmd\n",
    "\n",
    "# Choose a sample image (modify path as needed)\n",
    "sample_image = os.path.join(rec_dataset_dir, \"images/sample.jpg\")\n",
    "if not os.path.exists(sample_image):\n",
    "    # Try to find any image\n",
    "    sample_images = glob.glob(os.path.join(rec_dataset_dir, \"images/*.jpg\"))\n",
    "    if sample_images:\n",
    "        sample_image = sample_images[0]\n",
    "        print(f\"Using sample image: {sample_image}\")\n",
    "    else:\n",
    "        print(\"No sample images found for inference.\")\n",
    "        sample_image = None\n",
    "\n",
    "if sample_image:\n",
    "    infer_cmd = generate_infer_cmd(config, sample_image)\n",
    "    print(\"Inference command:\")\n",
    "    print(infer_cmd)\n",
    "    \n",
    "    # Uncomment to run inference\n",
    "    # print(\"Running inference...\")\n",
    "    # run_with_output(infer_cmd)\n",
    "    # print(\"Inference result should be displayed above.\")\n",
    "\n",
    "# ## 12. Export Model for Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export the model for deployment\n",
    "def generate_export_cmd(config):\n",
    "    \"\"\"Generate model export command\"\"\"\n",
    "    model_dir = config[\"model_save_dir\"]\n",
    "    export_dir = os.path.join(model_dir, \"inference\")\n",
    "    export_cmd = f\"\"\"python tools/export_model.py \\\n",
    "        -c configs/rec/meter/meter_PP-OCRv3_rec.yml \\\n",
    "        -o Global.pretrained_model={model_dir}/best_accuracy \\\n",
    "        Global.save_inference_dir={export_dir} \\\n",
    "        Global.character_dict_path={config[\"dict_path\"]}\"\"\"\n",
    "    return export_cmd\n",
    "\n",
    "export_cmd = generate_export_cmd(config)\n",
    "print(\"Export command:\")\n",
    "print(export_cmd)\n",
    "\n",
    "# Uncomment to export model\n",
    "# print(\"Exporting model...\")\n",
    "# run_with_output(export_cmd) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
