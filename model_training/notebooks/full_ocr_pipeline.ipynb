{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Full Meter Reading OCR Pipeline\n",
    "# \n",
    "# This notebook demonstrates the complete OCR pipeline, combining detection and recognition models.\n",
    "\n",
    "# ## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b750fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import subprocess\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, Image, clear_output\n",
    "\n",
    "# Ensure we're in the PaddleOCR root directory\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"../..\"))\n",
    "os.chdir(ROOT_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "\n",
    "# Check if key directories exist\n",
    "assert os.path.exists('ppocr'), \"Not in PaddleOCR root directory!\"\n",
    "assert os.path.exists('tools'), \"PaddleOCR tools directory not found!\"\n",
    "\n",
    "# ## 2. Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configuration for detection and recognition models\n",
    "config = {\n",
    "    # Dataset paths\n",
    "    \"test_image_dir\": \"dataset/det_dataset_1/images\",\n",
    "    \"det_model_dir\": \"model_training/det_train/output/meter_student\",\n",
    "    \"rec_model_dir\": \"model_training/rec_train/output/meter_rec\",\n",
    "    \"dict_path\": \"model_training/rec_train/meter_dict.txt\",\n",
    "    \n",
    "    # Model selection\n",
    "    \"det_model_type\": \"student\",  # \"teacher\" or \"student\"\n",
    "    \"rec_model_type\": \"standard\", # \"standard\" or \"distillation\"\n",
    "    \n",
    "    # Config files\n",
    "    \"det_config\": \"configs/det/ch_PP-OCRv3/ch_PP-OCRv3_det_teacher.yml\",\n",
    "    \"rec_config\": \"configs/rec/meter/meter_PP-OCRv3_rec.yml\",\n",
    "    \n",
    "    # Output directory\n",
    "    \"output_dir\": \"inference_results\"\n",
    "}\n",
    "\n",
    "# Adjust paths based on model types\n",
    "if config[\"det_model_type\"] == \"teacher\":\n",
    "    config[\"det_model_dir\"] = \"model_training/det_train/output/meter_teacher\"\n",
    "\n",
    "if config[\"rec_model_type\"] == \"distillation\":\n",
    "    config[\"rec_model_dir\"] = \"model_training/rec_train/output/meter_rec_distillation\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
    "\n",
    "# Print configuration\n",
    "print(\"Pipeline Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# ## 3. Check Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390d68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if detection model exists\n",
    "det_model = os.path.join(config[\"det_model_dir\"], \"best_accuracy.pdparams\")\n",
    "if not os.path.exists(det_model):\n",
    "    print(f\"Warning: Detection model not found at {det_model}\")\n",
    "    print(\"You need to train a detection model first.\")\n",
    "else:\n",
    "    print(f\"Detection model found at {det_model}\")\n",
    "\n",
    "# Check if recognition model exists\n",
    "rec_model = os.path.join(config[\"rec_model_dir\"], \"best_accuracy.pdparams\")\n",
    "if not os.path.exists(rec_model):\n",
    "    print(f\"Warning: Recognition model not found at {rec_model}\")\n",
    "    print(\"You need to train a recognition model first.\")\n",
    "else:\n",
    "    print(f\"Recognition model found at {rec_model}\")\n",
    "\n",
    "# Check character dictionary\n",
    "if not os.path.exists(config[\"dict_path\"]):\n",
    "    print(f\"Warning: Character dictionary not found at {config['dict_path']}\")\n",
    "    print(\"Make sure you have created the character dictionary.\")\n",
    "else:\n",
    "    with open(config[\"dict_path\"], 'r') as f:\n",
    "        chars = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"Character dictionary found with {len(chars)} characters: {''.join(chars)}\")\n",
    "\n",
    "# ## 4. Find Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find test images\n",
    "test_images = glob.glob(os.path.join(config[\"test_image_dir\"], \"*.jpg\"))\n",
    "if not test_images:\n",
    "    print(f\"No test images found in {config['test_image_dir']}\")\n",
    "    # Try to find images in any subdirectory\n",
    "    test_images = glob.glob(os.path.join(config[\"test_image_dir\"], \"**/*.jpg\"), recursive=True)\n",
    "    if not test_images:\n",
    "        print(\"No test images found in any subdirectory.\")\n",
    "\n",
    "if test_images:\n",
    "    print(f\"Found {len(test_images)} test images.\")\n",
    "    print(f\"First few images: {test_images[:3]}\")\n",
    "    \n",
    "    # Display a sample image\n",
    "    sample_image = test_images[0]\n",
    "    print(f\"Sample image: {sample_image}\")\n",
    "    display(Image(filename=sample_image))\n",
    "else:\n",
    "    print(\"Please specify a valid directory with test images.\")\n",
    "\n",
    "# ## 5. Detection Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c8e058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run detection inference on a sample image\n",
    "def run_detection(image_path, config):\n",
    "    \"\"\"Run detection on a single image\"\"\"\n",
    "    det_cmd = f\"\"\"python tools/infer_det.py \\\n",
    "        -c {config[\"det_config\"]} \\\n",
    "        -o Global.infer_img={image_path} \\\n",
    "        Global.checkpoints={config[\"det_model_dir\"]}/best_accuracy \\\n",
    "        Global.save_res_path={config[\"output_dir\"]}/det_results.txt\"\"\"\n",
    "    \n",
    "    print(f\"Running detection on {os.path.basename(image_path)}...\")\n",
    "    print(f\"Command: {det_cmd}\")\n",
    "    \n",
    "    # Uncomment to run detection\n",
    "    # subprocess.run(det_cmd, shell=True)\n",
    "    # \n",
    "    # # Display result if available\n",
    "    # result_image = os.path.join(config[\"output_dir\"], \"det_res.jpg\")\n",
    "    # if os.path.exists(result_image):\n",
    "    #     print(\"Detection result:\")\n",
    "    #     display(Image(filename=result_image))\n",
    "    # else:\n",
    "    #     print(f\"Result image not found: {result_image}\")\n",
    "    \n",
    "    return os.path.join(config[\"output_dir\"], \"det_res.jpg\")\n",
    "\n",
    "# Choose a sample image for detection\n",
    "if test_images:\n",
    "    sample_det_image = test_images[0]\n",
    "    print(f\"Sample image for detection: {sample_det_image}\")\n",
    "    # Uncomment to run\n",
    "    # det_result = run_detection(sample_det_image, config)\n",
    "\n",
    "# ## 6. Recognition Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be03472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run recognition on cropped regions\n",
    "def run_recognition(image_path, config):\n",
    "    \"\"\"Run recognition on a cropped image\"\"\"\n",
    "    rec_cmd = f\"\"\"python tools/infer_rec.py \\\n",
    "        -c {config[\"rec_config\"]} \\\n",
    "        -o Global.infer_img={image_path} \\\n",
    "        Global.checkpoints={config[\"rec_model_dir\"]}/best_accuracy \\\n",
    "        Global.character_dict_path={config[\"dict_path\"]}\"\"\"\n",
    "    \n",
    "    print(f\"Running recognition on {os.path.basename(image_path)}...\")\n",
    "    print(f\"Command: {rec_cmd}\")\n",
    "    \n",
    "    # Uncomment to run recognition\n",
    "    # process = subprocess.Popen(rec_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)\n",
    "    # output = \"\"\n",
    "    # for line in iter(process.stdout.readline, ''):\n",
    "    #     print(line, end='')\n",
    "    #     output += line\n",
    "    # process.wait()\n",
    "    \n",
    "    # # Parse and return recognition result\n",
    "    # # This is a simple parsing, adjust based on actual output format\n",
    "    # if \"result\" in output:\n",
    "    #     result_line = [l for l in output.split('\\n') if \"result\" in l]\n",
    "    #     if result_line:\n",
    "    #         return result_line[0].split(\"result: \")[1].strip()\n",
    "    \n",
    "    return \"Recognition result would appear here\"\n",
    "\n",
    "# For demonstration, we would typically run this on detected regions\n",
    "# But for simplicity, we'll just use a sample test image\n",
    "if test_images:\n",
    "    sample_rec_image = test_images[0]\n",
    "    print(f\"Sample image for recognition: {sample_rec_image}\")\n",
    "    # Uncomment to run\n",
    "    # rec_result = run_recognition(sample_rec_image, config)\n",
    "    # print(f\"Recognition result: {rec_result}\")\n",
    "\n",
    "# ## 7. Full OCR Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bf3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run complete OCR pipeline on an image\n",
    "def run_full_ocr(image_path, config):\n",
    "    \"\"\"Run full OCR pipeline (detection + recognition) on an image\"\"\"\n",
    "    ocr_cmd = f\"\"\"python tools/infer.py \\\n",
    "        -c {config[\"det_config\"]} \\\n",
    "        -o Global.infer_img={image_path} \\\n",
    "        Global.use_gpu=true \\\n",
    "        Global.det_algorithm=DB \\\n",
    "        Global.det_model_dir={config[\"det_model_dir\"]} \\\n",
    "        Global.rec_algorithm=SVTR_LCNet \\\n",
    "        Global.rec_model_dir={config[\"rec_model_dir\"]} \\\n",
    "        Global.rec_char_dict_path={config[\"dict_path\"]} \\\n",
    "        Global.save_res_path={config[\"output_dir\"]}/ocr_result.txt \\\n",
    "        Global.vis_font_path=./doc/fonts/simfang.ttf\"\"\"\n",
    "    \n",
    "    print(f\"Running full OCR pipeline on {os.path.basename(image_path)}...\")\n",
    "    print(f\"Command: {ocr_cmd}\")\n",
    "    \n",
    "    # Uncomment to run the full pipeline\n",
    "    # subprocess.run(ocr_cmd, shell=True)\n",
    "    # \n",
    "    # # Display result if available\n",
    "    # result_image = image_path.replace(os.path.basename(image_path), \"inference_results\")\n",
    "    # result_image = os.path.join(os.path.dirname(result_image), os.path.basename(image_path))\n",
    "    # if os.path.exists(result_image):\n",
    "    #     print(\"OCR result:\")\n",
    "    #     display(Image(filename=result_image))\n",
    "    # else:\n",
    "    #     print(f\"Result image not found: {result_image}\")\n",
    "    #     # Try alternative path\n",
    "    #     result_image = os.path.join(config[\"output_dir\"], os.path.basename(image_path))\n",
    "    #     if os.path.exists(result_image):\n",
    "    #         print(\"OCR result:\")\n",
    "    #         display(Image(filename=result_image))\n",
    "    \n",
    "    # Display the result text file if available\n",
    "    result_file = os.path.join(config[\"output_dir\"], \"ocr_result.txt\")\n",
    "    if os.path.exists(result_file):\n",
    "        with open(result_file, 'r') as f:\n",
    "            results = f.read()\n",
    "        print(\"OCR results:\")\n",
    "        print(results)\n",
    "    else:\n",
    "        print(f\"Result file not found: {result_file}\")\n",
    "\n",
    "# Choose a sample image for full OCR\n",
    "if test_images:\n",
    "    sample_ocr_image = test_images[0]\n",
    "    print(f\"Sample image for full OCR: {sample_ocr_image}\")\n",
    "    # Uncomment to run\n",
    "    # run_full_ocr(sample_ocr_image, config)\n",
    "\n",
    "# ## 8. Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dcdfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Process multiple images in batch\n",
    "def batch_process(image_list, config, max_images=5):\n",
    "    \"\"\"Process multiple images with full OCR pipeline\"\"\"\n",
    "    if not image_list:\n",
    "        print(\"No images provided for batch processing.\")\n",
    "        return\n",
    "    \n",
    "    # Limit number of images for demonstration\n",
    "    if len(image_list) > max_images:\n",
    "        print(f\"Limiting to {max_images} images for demonstration.\")\n",
    "        image_list = image_list[:max_images]\n",
    "    \n",
    "    print(f\"Processing {len(image_list)} images...\")\n",
    "    \n",
    "    results = []\n",
    "    for image_path in image_list:\n",
    "        print(f\"Processing {os.path.basename(image_path)}...\")\n",
    "        \n",
    "        # Run OCR pipeline\n",
    "        ocr_cmd = f\"\"\"python tools/infer.py \\\n",
    "            -c {config[\"det_config\"]} \\\n",
    "            -o Global.infer_img={image_path} \\\n",
    "            Global.use_gpu=true \\\n",
    "            Global.det_algorithm=DB \\\n",
    "            Global.det_model_dir={config[\"det_model_dir\"]} \\\n",
    "            Global.rec_algorithm=SVTR_LCNet \\\n",
    "            Global.rec_model_dir={config[\"rec_model_dir\"]} \\\n",
    "            Global.rec_char_dict_path={config[\"dict_path\"]} \\\n",
    "            Global.save_res_path={config[\"output_dir\"]}/batch_results/{os.path.basename(image_path)}.txt\"\"\"\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(os.path.join(config[\"output_dir\"], \"batch_results\"), exist_ok=True)\n",
    "        \n",
    "        # Uncomment to run\n",
    "        # subprocess.run(ocr_cmd, shell=True)\n",
    "        # \n",
    "        # # Read results\n",
    "        # result_file = f\"{config['output_dir']}/batch_results/{os.path.basename(image_path)}.txt\"\n",
    "        # if os.path.exists(result_file):\n",
    "        #     with open(result_file, 'r') as f:\n",
    "        #         ocr_result = f.read()\n",
    "        #     results.append((image_path, ocr_result))\n",
    "        # else:\n",
    "        #     results.append((image_path, \"No result file found\"))\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\nBatch processing summary:\")\n",
    "    for image_path, result in results:\n",
    "        print(f\"Image: {os.path.basename(image_path)}\")\n",
    "        print(f\"Result: {result[:100]}...\" if len(result) > 100 else f\"Result: {result}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Choose images for batch processing\n",
    "if test_images:\n",
    "    batch_images = test_images[:3]  # Take first 3 images for example\n",
    "    print(f\"Selected {len(batch_images)} images for batch processing:\")\n",
    "    for img in batch_images:\n",
    "        print(f\"  - {os.path.basename(img)}\")\n",
    "    \n",
    "    # Uncomment to run batch processing\n",
    "    # batch_process(batch_images, config)\n",
    "\n",
    "# ## 9. Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddff073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Export models for deployment\n",
    "def export_models(config):\n",
    "    \"\"\"Export detection and recognition models for deployment\"\"\"\n",
    "    # Export detection model\n",
    "    det_export_cmd = f\"\"\"python tools/export_model.py \\\n",
    "        -c {config[\"det_config\"]} \\\n",
    "        -o Global.pretrained_model={config[\"det_model_dir\"]}/best_accuracy \\\n",
    "        Global.save_inference_dir={config[\"det_model_dir\"]}/inference\"\"\"\n",
    "    \n",
    "    # Export recognition model\n",
    "    rec_export_cmd = f\"\"\"python tools/export_model.py \\\n",
    "        -c {config[\"rec_config\"]} \\\n",
    "        -o Global.pretrained_model={config[\"rec_model_dir\"]}/best_accuracy \\\n",
    "        Global.save_inference_dir={config[\"rec_model_dir\"]}/inference \\\n",
    "        Global.character_dict_path={config[\"dict_path\"]}\"\"\"\n",
    "    \n",
    "    print(\"Detection model export command:\")\n",
    "    print(det_export_cmd)\n",
    "    \n",
    "    print(\"\\nRecognition model export command:\")\n",
    "    print(rec_export_cmd)\n",
    "    \n",
    "    # Uncomment to run export\n",
    "    # print(\"\\nExporting detection model...\")\n",
    "    # subprocess.run(det_export_cmd, shell=True)\n",
    "    # \n",
    "    # print(\"\\nExporting recognition model...\")\n",
    "    # subprocess.run(rec_export_cmd, shell=True)\n",
    "    # \n",
    "    # # Check if export was successful\n",
    "    # if os.path.exists(os.path.join(config[\"det_model_dir\"], \"inference\", \"inference.pdmodel\")):\n",
    "    #     print(\"Detection model exported successfully.\")\n",
    "    # else:\n",
    "    #     print(\"Detection model export failed.\")\n",
    "    # \n",
    "    # if os.path.exists(os.path.join(config[\"rec_model_dir\"], \"inference\", \"inference.pdmodel\")):\n",
    "    #     print(\"Recognition model exported successfully.\")\n",
    "    # else:\n",
    "    #     print(\"Recognition model export failed.\")\n",
    "\n",
    "# Show export commands\n",
    "export_models(config)\n",
    "\n",
    "# ## 10. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Analyze performance of OCR system\n",
    "def analyze_performance(test_images, config, max_images=5):\n",
    "    \"\"\"Analyze performance on test images with ground truth\"\"\"\n",
    "    if not test_images:\n",
    "        print(\"No test images provided for analysis.\")\n",
    "        return\n",
    "    \n",
    "    # Limit number of images for demonstration\n",
    "    if len(test_images) > max_images:\n",
    "        print(f\"Limiting to {max_images} images for demonstration.\")\n",
    "        test_images = test_images[:max_images]\n",
    "    \n",
    "    # Create a table for results\n",
    "    results = []\n",
    "    header = [\"Image\", \"Detection Time (ms)\", \"Recognition Time (ms)\", \"Total Time (ms)\", \"Text Detected\"]\n",
    "    \n",
    "    # Uncomment to run performance analysis\n",
    "    # for image_path in test_images:\n",
    "    #     print(f\"Processing {os.path.basename(image_path)}...\")\n",
    "    #     \n",
    "    #     # Measure detection time\n",
    "    #     start_time = time.time()\n",
    "    #     det_cmd = f\"\"\"python tools/infer_det.py \\\n",
    "    #         -c {config[\"det_config\"]} \\\n",
    "    #         -o Global.infer_img={image_path} \\\n",
    "    #         Global.checkpoints={config[\"det_model_dir\"]}/best_accuracy\"\"\"\n",
    "    #     subprocess.run(det_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    #     det_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "    #     \n",
    "    #     # Get detection result\n",
    "    #     det_result_file = os.path.join(config[\"output_dir\"], \"det_results.txt\")\n",
    "    #     det_boxes = []\n",
    "    #     if os.path.exists(det_result_file):\n",
    "    #         with open(det_result_file, 'r') as f:\n",
    "    #             det_data = f.read()\n",
    "    #             # Parse detection boxes (format depends on output)\n",
    "    #             # This is placeholder parsing, adjust based on actual format\n",
    "    #             det_boxes = [line.split('\\t')[0] for line in det_data.split('\\n') if line]\n",
    "    #     \n",
    "    #     # Measure recognition time\n",
    "    #     start_time = time.time()\n",
    "    #     # We'll use the full image for simplicity\n",
    "    #     rec_cmd = f\"\"\"python tools/infer_rec.py \\\n",
    "    #         -c {config[\"rec_config\"]} \\\n",
    "    #         -o Global.infer_img={image_path} \\\n",
    "    #         Global.checkpoints={config[\"rec_model_dir\"]}/best_accuracy \\\n",
    "    #         Global.character_dict_path={config[\"dict_path\"]}\"\"\"\n",
    "    #     proc = subprocess.run(rec_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "    #     rec_time = (time.time() - start_time) * 1000  # Convert to ms\n",
    "    #     \n",
    "    #     # Extract recognized text\n",
    "    #     rec_output = proc.stdout\n",
    "    #     recognized_text = \"Unknown\"\n",
    "    #     # Parse recognition result (format depends on output)\n",
    "    #     # This is placeholder parsing, adjust based on actual format\n",
    "    #     if \"result\" in rec_output:\n",
    "    #         for line in rec_output.split('\\n'):\n",
    "    #             if \"result\" in line:\n",
    "    #                 recognized_text = line.split(\"result: \")[1].strip()\n",
    "    #                 break\n",
    "    #     \n",
    "    #     # Add to results\n",
    "    #     total_time = det_time + rec_time\n",
    "    #     results.append([os.path.basename(image_path), f\"{det_time:.1f}\", f\"{rec_time:.1f}\", f\"{total_time:.1f}\", recognized_text])\n",
    "    # \n",
    "    # # Display results table\n",
    "    # from tabulate import tabulate\n",
    "    # print(tabulate(results, headers=header, tablefmt=\"grid\"))\n",
    "    \n",
    "    # This is just a placeholder for demonstration\n",
    "    print(\"Performance analysis would analyze:\")\n",
    "    for img in test_images:\n",
    "        print(f\"  - {os.path.basename(img)}\")\n",
    "    print(\"\\nMetrics would include:\")\n",
    "    print(\"  - Detection time\")\n",
    "    print(\"  - Recognition time\")\n",
    "    print(\"  - Total processing time\")\n",
    "    print(\"  - Text detection accuracy\")\n",
    "    print(\"  - Text recognition accuracy\")\n",
    "\n",
    "# Run performance analysis if test images are available\n",
    "if test_images:\n",
    "    analyze_performance(test_images, config) "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# coding: utf-8",
   "executable": "/usr/bin/env python",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
